---
title: Markov Chains
category:
indexing: true
comments: true
excerpt: Markov Chains are powerful estimation tools that give a probability distribution for a next state only based on the current state. They are especially useful for understanding multivariate systems where an analytical solution cannot be reached.
author: Arthur York
---

Markov Chains

para 2

para 3
